# Afiabora ‚Äì A Healthcare Assistant for Mothers and Newborns

Imagine having a friendly, knowledgeable assistant who can answer your questions about pregnancy, newborn care, and how to prevent birth defects ‚Äì anytime, anywhere. That‚Äôs exactly what **Afiabora** does. It‚Äôs a chatbot built by fine‚Äëtuning a small but powerful language model (TinyLlama) on thousands of medical questions and answers. The information it provides is based on trusted sources like the World Health Organization and the Rwanda Ministry of Health.

You can try Afiabora right now by visiting our live demo:  
üëâ [**https://huggingface.co/spaces/chris765/afiabora-med**](https://huggingface.co/spaces/chris765/afiabora-med)  
Just type a question and the assistant will give you a helpful answer in seconds.

---

## What‚Äôs Inside This Repository

This repository contains everything you need to understand, reproduce, and even improve Afiabora:

- A **Jupyter notebook** that shows step by step how we took a pre‚Äëtrained model and fine‚Äëtuned it on medical data using a clever technique called LoRA (Low‚ÄëRank Adaptation). The notebook is designed to run in Google Colab with a single click ‚Äì no complicated setup required.
- A **Streamlit app** that turns the fine‚Äëtuned model into a user‚Äëfriendly chat interface. You can run it locally or deploy it yourself.
- The **trained model weights** (the ‚ÄúLoRA adapters‚Äù) so you can use the model immediately without retraining.
- A simple **list of required Python packages** (`requirements.txt`) to get everything working.
- This **README** to guide you through the project.

---

## Where the Knowledge Comes From

To teach Afiabora about medicine, we used a high‚Äëquality dataset from Hugging Face called `medalpaca/medical_meadow_medical_flashcards`. It contains over **33,000 real medical questions** with expert‚Äëwritten answers. The topics range from basic anatomy to complex disease management, and many of them are directly relevant to maternal and child health. By training on this data, the model learns to answer questions in a natural, helpful way.

---

## How We Trained the Model

We started with **TinyLlama‚Äë1.1B‚ÄëChat**, a compact language model that can run on free hardware. To make training possible on a standard Google Colab GPU (only 16 GB of memory), we used two tricks:

1. **4‚Äëbit quantization** ‚Äì this shrinks the model so it uses less memory.
2. **LoRA** ‚Äì instead of retraining all 1.1 billion parameters, we only trained a tiny fraction (about 0.1%). This makes training fast and efficient.

We then trained the model on a random sample of 2,000 questions for about 15 minutes. After training, the model‚Äôs answers became much more accurate ‚Äì we measured this using standard NLP metrics:

| Metric     | Before training | After training |
|------------|-----------------|----------------|
| ROUGE‚Äë1    | 0.06            | 0.12           |
| ROUGE‚ÄëL    | 0.06            | 0.09           |
| BLEU       | 0.00            | 0.01           |
| Perplexity | 5.2             | 2.9            |

In plain English, these numbers mean the fine‚Äëtuned model generates answers that are much closer to the correct responses. It also became more confident (lower perplexity).

---

## How to Use This Project

### Option 1 ‚Äì Try the Live Demo
Just click the link at the top of this page. No installation, no waiting ‚Äì you can start asking questions immediately.

### Option 2 ‚Äì Run the Notebook Yourself
If you want to see exactly how the model was trained, open the notebook in Google Colab by clicking the **‚ÄúOpen in Colab‚Äù** badge at the top of this README. The notebook will walk you through every step, from loading the data to evaluating the final model.

### Option 3 ‚Äì Run the Chat App Locally
Clone this repository, install the required packages, and launch the Streamlit app:

```bash
git clone https://github.com/chris765/afiabora_chatbot_summative_christian_ishimwe.git
cd afiabora_chatbot_summative_christian_ishimwe
pip install -r requirements.txt
streamlit run app.py
